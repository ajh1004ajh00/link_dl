{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[요구사항 1]\n",
    "---\n",
    "titanic_dataset.py 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/bg6gou1o?nw=nwuserajhajh503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset): # 데이터 셋을 상속받아 데이터를 load 하고 처리하기 쉽게 해줌\n",
    "  def __init__(self, X, y):\n",
    "    self.X = torch.FloatTensor(X) # floattensor로 변환해 저장하고 feature와 target 받음.\n",
    "    self.y = torch.LongTensor(y)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    feature = self.X[idx]\n",
    "    target = self.y[idx]\n",
    "    return {'input': feature, 'target': target}\n",
    "\n",
    "  def __str__(self):\n",
    "    str = \"Data Size: {0}, Input Shape: {1}, Target Shape: {2}\".format(\n",
    "      len(self.X), self.X.shape, self.y.shape\n",
    "    )\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicTestDataset(Dataset): # Test dataset에는 y 즉 target 값이 없으므로\n",
    "  def __init__(self, X): # x(입력) 값만 처리\n",
    "    self.X = torch.FloatTensor(X)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    feature = self.X[idx]\n",
    "    return {'input': feature}\n",
    "\n",
    "  def __str__(self):\n",
    "    str = \"Data Size: {0}, Input Shape: {1}\".format(\n",
    "      len(self.X), self.X.shape\n",
    "    )\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_1(all_df):\n",
    "    # Pclass별 Fare 평균값을 사용하여 Fare 결측치 메우기\n",
    "    #all_df[[\"Pclass\", \"Fare\"]] = 데이터셋에서 pclass, fare 열만 선택\n",
    "    #groupby(\"Pclass\") = pclass 열 기준으로 데이터를 그룹화\n",
    "    #즉, 1,2,3 등급별로 그룹이 만들어짐.\n",
    "    #mean()은 평균\n",
    "    #reset_index()은 열로 변환하여 데이터프레임 형태로 만들어줌\n",
    "    Fare_mean = all_df[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").mean().reset_index()\n",
    "    \n",
    "    Fare_mean.columns = [\"Pclass\", \"Fare_mean\"]#열이름을 pclass, fare_mean으로 변경\n",
    "    #all_df 원래 데이터셋과 방금 만든 fare_mean 데이터셋을 결합\n",
    "    #on=\"Pclass\"열 기준으로 병합. left 즉 왼쪽 모든 데이터를 유지하면서 병합\n",
    "    all_df = pd.merge(all_df, Fare_mean, on=\"Pclass\", how=\"left\")\n",
    "    #all_df[\"Fare\"].isnull() Fare 값이 없는 데이터를 찾아\n",
    "    #loc으로 맞는 행을 선택하고, \n",
    "    # #all_df[\"Fare\"] = all_df[\"Fare_mean\"] 없는 Fare 값을 Fare_mean 값으로 대체\n",
    "    all_df.loc[(all_df[\"Fare\"].isnull()), \"Fare\"] = all_df[\"Fare_mean\"]\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_2(all_df):\n",
    "    # name을 세 개의 컬럼으로 분리하여 다시 all_df에 합침\n",
    "    #학습할 때 필요없는 특징\n",
    "    #다만 나이의 평균 값을 구할 때, 존칭을 이용해 평균 나이값을 구하기 때문에\n",
    "    #honorific은 의미 있는 특징이 됨\n",
    "    name_df = all_df[\"Name\"].str.split(\"[,.]\", n=2, expand=True)\n",
    "    name_df.columns = [\"family_name\", \"honorific\", \"name\"]\n",
    "    name_df[\"family_name\"] = name_df[\"family_name\"].str.strip()\n",
    "    name_df[\"honorific\"] = name_df[\"honorific\"].str.strip()\n",
    "    name_df[\"name\"] = name_df[\"name\"].str.strip()\n",
    "    all_df = pd.concat([all_df, name_df], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_3(all_df):\n",
    "    # honorific별 Age 평균값을 사용하여 Age 결측치 메우기\n",
    "    # 존칭(Mr,Mrs)으로 그룹을 나눠 없는 데이터 셋에 평균 나이를 추가.\n",
    "    #방식은 fare와 유사.\n",
    "    honorific_age_mean = all_df[[\"honorific\", \"Age\"]].groupby(\"honorific\").median().round().reset_index()\n",
    "    honorific_age_mean.columns = [\"honorific\", \"honorific_age_mean\", ]\n",
    "    all_df = pd.merge(all_df, honorific_age_mean, on=\"honorific\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Age\"].isnull()), \"Age\"] = all_df[\"honorific_age_mean\"]\n",
    "\n",
    "    # drop([\"honorific_age_mean\"], axis=1) = 해당 열 삭제.    \n",
    "    all_df = all_df.drop([\"honorific_age_mean\"], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_4(all_df):\n",
    "    # 가족수(family_num) 컬럼 새롭게 추가\n",
    "    #가족의 수 = 부모와 자녀 + 형제자매와 배우자 수\n",
    "    all_df[\"family_num\"] = all_df[\"Parch\"] + all_df[\"SibSp\"]\n",
    "\n",
    "    # 혼자탑승(alone) 컬럼 새롭게 추가\n",
    "    #가족수가 0이면 alone 새 열을 만들어 1 할당\n",
    "    all_df.loc[all_df[\"family_num\"] == 0, \"alone\"] = 1\n",
    "    #alone 값이 0 즉 결측값이면 0으로 채워줌\n",
    "    #all_df[\"alone\"].fillna(0, inplace=True)\n",
    "    all_df[\"alone\"] = all_df[\"alone\"].fillna(0)\n",
    "\n",
    "    # 학습에 불필요한 컬럼 제거 \n",
    "    all_df = all_df.drop([\"PassengerId\", \"Name\", \"family_name\", \"name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_5(all_df):\n",
    "    # honorific 값 개수 줄이기\n",
    "    # ~(...)은 부정 연산자로 안에 조건이 들어감.\n",
    "    # 조건을 만족하지 않는 경우 other로 대체됨\n",
    "    all_df.loc[\n",
    "    ~(\n",
    "            (all_df[\"honorific\"] == \"Mr\") |\n",
    "            (all_df[\"honorific\"] == \"Miss\") |\n",
    "            (all_df[\"honorific\"] == \"Mrs\") |\n",
    "            (all_df[\"honorific\"] == \"Master\")\n",
    "    ),\n",
    "    \"honorific\"\n",
    "    ] = \"other\"\n",
    "\n",
    "    #embarked 값이 없는경우 missing이라는 값을 할당. \n",
    "    #all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n",
    "    all_df[\"Embarked\"] = all_df[\"Embarked\"].fillna(\"missing\")\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#카테고리별 변수들을 수치화 값으로 변환하는 함수\n",
    "\n",
    "def get_preprocessed_dataset_6(all_df):\n",
    "    # 범주형 변수를 LabelEncoder를 사용하여 수치값으로 변경하기\n",
    "    # all_df.columns 모든 열을 반환해서\n",
    "    #object 즉 문자열인 열만 모아서 category_features에 저장\n",
    "    category_features = all_df.columns[all_df.dtypes == \"object\"]\n",
    "    #범주형 데이터를 수치형으로 반환해주는 라이브러리\n",
    "    #각 범주형 데이터들을 고유한 정수로 변환해주는 for문\n",
    "    for category_feature in category_features: # 범주형 데이터들을 하나씩 뽑아서\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        #범주형 데이터면\n",
    "        if all_df[category_feature].dtypes == \"object\":\n",
    "          #고유한 정수로 맵핑\n",
    "          le = le.fit(all_df[category_feature])\n",
    "          #범주형 데이터를 수치형으로 변환.\n",
    "          all_df[category_feature] = le.transform(all_df[category_feature])\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터의 전처리와 분할을 담당하는 파트.\n",
    "def get_preprocessed_dataset():\n",
    "    #CURRENT_FILE_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "    # __file__변수는 스크립트 파일 경로이지만 쥬피터 노트북으로 변경했기 때문에\n",
    "    #자동으로 정의되지 않음. 따라서 현재 작업 디렉토리를 직접 설정해줘야함.\n",
    "    CURRENT_FILE_PATH = os.getcwd()  # 현재 디렉토리 경로 사용\n",
    "    train_data_path = os.path.join(CURRENT_FILE_PATH, \"train.csv\") # 파일을 연결\n",
    "    test_data_path = os.path.join(CURRENT_FILE_PATH, \"test.csv\")\n",
    "\n",
    "    train_df = pd.read_csv(train_data_path) # 데이터 load\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "    #한번에 전처리 하기 위해서 단순히 뒤에 이어 붙이는 concat 사용\n",
    "    #train에는 label인 survived가 있지만 test에는 없는걸 고려해서 처리해야함. \n",
    "    all_df = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_1(all_df) #fare 결측값 처리리\n",
    "\n",
    "    all_df = get_preprocessed_dataset_2(all_df) #이름 분리\n",
    "\n",
    "    all_df = get_preprocessed_dataset_3(all_df) # age 결측값 추가가\n",
    "\n",
    "    all_df = get_preprocessed_dataset_4(all_df) # 가족, 필요없는 특징 제거\n",
    "\n",
    "    all_df = get_preprocessed_dataset_5(all_df) # embarked 결측값 추가 및 honorific 값 개수 줄이기\n",
    "\n",
    "    all_df = get_preprocessed_dataset_6(all_df) # 범주형 특징값들을 고유한 수치로 맵핑\n",
    "\n",
    "    #concat으로 붙여놨던 train 데이터와 test 데이터를 분리하는 작업\n",
    "    # train 데이터를 validation 데이터도 분리\n",
    "    #survived 값이 결측값 = test 데이터 이므로 부정 연산자를 사용해\n",
    "    # survived 값이 있는 데이터를 train x에 추가.\n",
    "    #drop을 사용해 target 인 survived를 제거\n",
    "    #reset_index(drop=True) 기존 인덱스에 새로운 열을 추가하지 않고 완전 제거 후 인덱스 재설정\n",
    "    train_X = all_df[~all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "    train_y = train_df[\"Survived\"]\n",
    "\n",
    "    # ~ 부정 연산자만 빼서 survived가 없는 데이터를 test x에 추가.\n",
    "    test_X = all_df[all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "\n",
    "    # 입력과 출력(target)으로 데이터 셋 구성\n",
    "    dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "    #print(dataset)\n",
    "    #데이터 셋을 8:2로 train 데이터와 validation 데이터를 분리\n",
    "    train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2])\n",
    "    test_dataset = TitanicTestDataset(test_X.values)\n",
    "    #print(test_dataset)\n",
    "    # 데이터 셋을 train, validation, test로 분리후 반환\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 구조 정의하는 파트\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  #n_input = 입력 특징의 개수\n",
    "  #n_output = survived 여부 즉 0 or 1\n",
    "  def __init__(self, n_input, n_output): # 모델 구조 정의\n",
    "    super().__init__()\n",
    "\n",
    "    #순차적으로 레이어를 정의\n",
    "    #FCL이고 활성화 함수는 Relu 사용\n",
    "    # x의 특징 수 11를 입력으로 받아\n",
    "    # 30개로 선형 변환 후 히든레이어 하나 더 지나 0 or 1이 출력됨\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(n_input, 30),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(30, 30),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(30, n_output),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_data_loader):\n",
    "  print(\"[TEST]\")\n",
    "  #데이터를 배치 단위로 반복\n",
    "  batch = next(iter(test_data_loader))\n",
    "  print(\"{0}\".format(batch['input'].shape))\n",
    "  #print(\"{0}\".format(batch['input']))\n",
    "  # 특징 수 11개와 0 or 1을 출력하는 모델 생성\n",
    "  my_model = MyModel(n_input=11, n_output=2)\n",
    "\n",
    "  #입력데이터를 넣어 예측을 수행.\n",
    "  output_batch = my_model(batch['input'])\n",
    "  #dim 1 즉, 0 or 1 중 더 예측값이 높은거 하나 선택\n",
    "  prediction_batch = torch.argmax(output_batch, dim=1)\n",
    "\n",
    "  #예측한 값 출력\n",
    "  #for idx, prediction in enumerate(prediction_batch, start=892):\n",
    "  #    print(idx, prediction.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 713, validation_dataset.shape: 178, test_dataset: 418\n",
      "################################################## 1\n",
      "0 - tensor([ 2.0000,  1.0000, 32.0000,  2.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "1 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "2 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "3 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 40.1250,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "4 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "5 - tensor([ 3.0000,  0.0000, 31.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "6 - tensor([ 3.0000,  1.0000, 55.5000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "7 - tensor([ 2.0000,  0.0000, 33.0000,  0.0000,  2.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "8 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "9 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "10 - tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "11 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "12 - tensor([ 3.0000,  0.0000, 18.0000,  1.0000,  0.0000, 17.8000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "13 - tensor([  1.0000,   0.0000,  58.0000,   0.0000,   0.0000, 146.5208,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "14 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "15 - tensor([ 3.0000,  1.0000,  0.4200,  0.0000,  1.0000,  8.5167,  0.0000, 13.3029,\n",
      "         0.0000,  1.0000,  0.0000]): 1\n",
      "16 - tensor([ 2.0000,  0.0000,  3.0000,  1.0000,  2.0000, 41.5792,  0.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "17 - tensor([ 1.0000,  0.0000, 26.0000,  0.0000,  0.0000, 78.8500,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "18 - tensor([ 2.0000,  1.0000, 52.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "19 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "20 - tensor([ 2.0000,  1.0000, 43.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "21 - tensor([ 1.0000,  0.0000, 58.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "22 - tensor([ 3.0000,  1.0000,  2.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "23 - tensor([ 3.0000,  0.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "24 - tensor([ 3.0000,  1.0000, 20.0000,  1.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "25 - tensor([ 3.0000,  0.0000, 10.0000,  0.0000,  2.0000, 24.1500,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "26 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "27 - tensor([ 2.0000,  1.0000, 30.0000,  1.0000,  0.0000, 24.0000,  0.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "28 - tensor([ 3.0000,  0.0000, 23.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "29 - tensor([ 2.0000,  1.0000, 36.5000,  0.0000,  2.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "30 - tensor([ 2.0000,  0.0000, 27.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "31 - tensor([ 1.0000,  1.0000, 46.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "32 - tensor([ 1.0000,  1.0000, 40.0000,  0.0000,  0.0000, 31.0000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "33 - tensor([ 1.0000,  1.0000, 42.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "34 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "35 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "36 - tensor([ 2.0000,  1.0000, 25.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "37 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "38 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 69.3000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "39 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "40 - tensor([ 3.0000,  0.0000,  4.0000,  1.0000,  1.0000, 16.7000,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "41 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "42 - tensor([ 2.0000,  1.0000,  1.0000,  2.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         0.0000,  3.0000,  0.0000]): 1\n",
      "43 - tensor([ 3.0000,  0.0000, 33.0000,  3.0000,  0.0000, 15.8500,  2.0000, 13.3029,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "44 - tensor([  1.0000,   0.0000,  15.0000,   0.0000,   1.0000, 211.3375,   2.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "45 - tensor([ 2.0000,  0.0000, 28.0000,  0.0000,  0.0000, 12.6500,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "46 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 19.9667,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "47 - tensor([ 2.0000,  0.0000, 28.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "48 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "49 - tensor([ 3.0000,  0.0000, 38.0000,  1.0000,  5.0000, 31.3875,  2.0000, 13.3029,\n",
      "         3.0000,  6.0000,  0.0000]): 1\n",
      "50 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "51 - tensor([ 3.0000,  0.0000,  2.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         1.0000,  5.0000,  0.0000]): 0\n",
      "52 - tensor([ 2.0000,  1.0000, 27.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "53 - tensor([ 2.0000,  0.0000, 25.0000,  1.0000,  1.0000, 30.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "54 - tensor([ 2.0000,  1.0000, 19.0000,  1.0000,  1.0000, 36.7500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "55 - tensor([ 3.0000,  0.0000, 13.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "56 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "57 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "58 - tensor([ 3.0000,  1.0000, 40.0000,  1.0000,  4.0000, 27.9000,  2.0000, 13.3029,\n",
      "         2.0000,  5.0000,  0.0000]): 0\n",
      "59 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 83.1583,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "60 - tensor([ 3.0000,  1.0000, 10.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "61 - tensor([  1.0000,   1.0000,   0.9200,   1.0000,   2.0000, 151.5500,   2.0000,\n",
      "         87.5090,   0.0000,   3.0000,   0.0000]): 1\n",
      "62 - tensor([ 2.0000,  1.0000, 46.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "63 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000,  7.0458,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "64 - tensor([  1.0000,   0.0000,  25.0000,   1.0000,   2.0000, 151.5500,   2.0000,\n",
      "         87.5090,   3.0000,   3.0000,   0.0000]): 0\n",
      "65 - tensor([  1.0000,   1.0000,  29.0000,   0.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 0\n",
      "66 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  2.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "67 - tensor([ 2.0000,  0.0000, 24.0000,  1.0000,  2.0000, 65.0000,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "68 - tensor([ 3.0000,  0.0000, 45.0000,  0.0000,  1.0000, 14.4542,  0.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "69 - tensor([ 3.0000,  0.0000, 23.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "70 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "71 - tensor([ 3.0000,  0.0000, 41.0000,  0.0000,  5.0000, 39.6875,  2.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "72 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "73 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "74 - tensor([  1.0000,   1.0000,  50.0000,   2.0000,   0.0000, 133.6500,   2.0000,\n",
      "         87.5090,   4.0000,   2.0000,   0.0000]): 1\n",
      "75 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "76 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "77 - tensor([ 1.0000,  0.0000, 44.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "78 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "79 - tensor([ 2.0000,  0.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "80 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "81 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.4583,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "82 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.7417,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "83 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "84 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.1583,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "85 - tensor([  1.0000,   0.0000,  50.0000,   0.0000,   1.0000, 247.5208,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "86 - tensor([ 1.0000,  1.0000, 48.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "87 - tensor([  1.0000,   0.0000,  30.0000,   0.0000,   0.0000, 106.4250,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "88 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.6292,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "89 - tensor([ 3.0000,  0.0000,  8.0000,  3.0000,  1.0000, 21.0750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "90 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "91 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "92 - tensor([ 1.0000,  1.0000, 28.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "93 - tensor([  1.0000,   1.0000,  22.0000,   0.0000,   0.0000, 135.6333,   0.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 0\n",
      "94 - tensor([ 1.0000,  1.0000,  4.0000,  0.0000,  2.0000, 81.8583,  2.0000, 87.5090,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "95 - tensor([ 2.0000,  1.0000, 16.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "96 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "97 - tensor([ 1.0000,  1.0000, 45.0000,  1.0000,  0.0000, 83.4750,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "98 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "99 - tensor([  1.0000,   1.0000,  27.0000,   0.0000,   2.0000, 211.5000,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "100 - tensor([ 1.0000,  1.0000, 54.0000,  0.0000,  0.0000, 51.8625,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "101 - tensor([  1.0000,   0.0000,  58.0000,   0.0000,   1.0000, 153.4625,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "102 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "103 - tensor([ 2.0000,  0.0000, 24.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "104 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "105 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  9.2250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "106 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "107 - tensor([ 1.0000,  0.0000, 54.0000,  1.0000,  0.0000, 78.2667,  0.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "108 - tensor([ 1.0000,  1.0000, 48.0000,  1.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "109 - tensor([ 2.0000,  1.0000, 60.0000,  1.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "110 - tensor([ 3.0000,  1.0000, 14.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         2.0000,  5.0000,  0.0000]): 0\n",
      "111 - tensor([ 1.0000,  0.0000, 56.0000,  0.0000,  1.0000, 83.1583,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "112 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  2.0000, 22.3583,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "113 - tensor([ 2.0000,  0.0000, 44.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "114 - tensor([ 3.0000,  0.0000,  2.0000,  0.0000,  1.0000, 12.2875,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "115 - tensor([ 2.0000,  1.0000, 29.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "116 - tensor([ 3.0000,  1.0000,  7.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "117 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  1.0000, 33.0000,  2.0000, 21.1792,\n",
      "         4.0000,  1.0000,  0.0000]): 0\n",
      "118 - tensor([ 3.0000,  1.0000, 40.5000,  0.0000,  2.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "119 - tensor([ 3.0000,  0.0000, 16.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "120 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "121 - tensor([ 3.0000,  1.0000, 40.5000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "122 - tensor([ 1.0000,  0.0000, 33.0000,  0.0000,  0.0000, 86.5000,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "123 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "124 - tensor([ 1.0000,  1.0000, 27.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "125 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "126 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  1.0000,  8.4042,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "127 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8292,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "128 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "129 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  2.0000, 15.2458,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "130 - tensor([ 2.0000,  0.0000, 17.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "131 - tensor([  1.0000,   0.0000,  24.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   1.0000,   5.0000,   0.0000]): 1\n",
      "132 - tensor([  1.0000,   1.0000,  50.0000,   1.0000,   0.0000, 106.4250,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "133 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "134 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "135 - tensor([ 1.0000,  1.0000, 36.0000,  1.0000,  0.0000, 78.8500,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "136 - tensor([ 2.0000,  1.0000,  0.6700,  1.0000,  1.0000, 14.5000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "137 - tensor([ 2.0000,  1.0000,  8.0000,  1.0000,  1.0000, 36.7500,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "138 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.5208,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "139 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "140 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  9.8417,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "141 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "142 - tensor([ 1.0000,  0.0000, 33.0000,  1.0000,  0.0000, 90.0000,  1.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "143 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "144 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "145 - tensor([ 2.0000,  1.0000, 52.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "146 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "147 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 24.1500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "148 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  1.0000, 22.3583,  0.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "149 - tensor([  1.0000,   1.0000,  18.0000,   1.0000,   0.0000, 108.9000,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "150 - tensor([ 1.0000,  0.0000, 22.0000,  0.0000,  1.0000, 55.0000,  2.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "151 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "152 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "153 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 89.1042,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "154 - tensor([  1.0000,   0.0000,  29.0000,   0.0000,   0.0000, 211.3375,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "155 - tensor([ 2.0000,  0.0000, 22.0000,  1.0000,  2.0000, 41.5792,  0.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "156 - tensor([ 1.0000,  1.0000, 62.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "157 - tensor([ 2.0000,  1.0000, 42.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "158 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "159 - tensor([ 2.0000,  1.0000, 31.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "160 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  8.1375,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "161 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "162 - tensor([ 2.0000,  1.0000, 57.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "163 - tensor([ 1.0000,  1.0000, 35.0000,  0.0000,  0.0000, 26.5500,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "164 - tensor([ 2.0000,  0.0000, 28.0000,  1.0000,  0.0000, 24.0000,  0.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "165 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000, 17.8000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "166 - tensor([ 3.0000,  0.0000, 31.0000,  1.0000,  0.0000, 18.0000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "167 - tensor([ 3.0000,  1.0000,  8.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "168 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "169 - tensor([ 2.0000,  1.0000, 32.5000,  1.0000,  0.0000, 30.0708,  0.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "170 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "171 - tensor([ 3.0000,  0.0000,  9.0000,  2.0000,  2.0000, 34.3750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "172 - tensor([ 3.0000,  0.0000, 19.0000,  1.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "173 - tensor([ 2.0000,  1.0000,  0.8300,  1.0000,  1.0000, 18.7500,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "174 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "175 - tensor([ 3.0000,  0.0000, 45.0000,  1.0000,  4.0000, 27.9000,  2.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "176 - tensor([ 3.0000,  0.0000, 47.0000,  1.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "177 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "178 - tensor([  1.0000,   1.0000,  24.0000,   0.0000,   1.0000, 247.5208,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "179 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "180 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "181 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "182 - tensor([ 1.0000,  1.0000, 31.0000,  1.0000,  0.0000, 57.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "183 - tensor([ 2.0000,  0.0000, 33.0000,  1.0000,  2.0000, 27.7500,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "184 - tensor([ 2.0000,  0.0000, 24.0000,  2.0000,  1.0000, 27.0000,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "185 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "186 - tensor([ 2.0000,  0.0000,  8.0000,  0.0000,  2.0000, 26.2500,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "187 - tensor([ 2.0000,  1.0000,  3.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "188 - tensor([ 3.0000,  1.0000, 70.5000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "189 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "190 - tensor([ 2.0000,  1.0000, 26.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "191 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.3125,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "192 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 49.5042,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "193 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 26.3875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "194 - tensor([ 3.0000,  0.0000,  4.0000,  0.0000,  1.0000, 13.4167,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "195 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 13.8625,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "196 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "197 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "198 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 42.4000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "199 - tensor([ 3.0000,  1.0000, 15.0000,  1.0000,  1.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "200 - tensor([ 1.0000,  1.0000, 24.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "201 - tensor([ 2.0000,  1.0000, 66.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "202 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "203 - tensor([ 2.0000,  1.0000, 24.0000,  2.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "204 - tensor([ 1.0000,  1.0000, 32.0000,  0.0000,  0.0000, 30.5000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "205 - tensor([ 3.0000,  1.0000, 30.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "206 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 35.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "207 - tensor([ 2.0000,  1.0000, 25.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "208 - tensor([ 3.0000,  1.0000,  3.0000,  4.0000,  2.0000, 31.3875,  2.0000, 13.3029,\n",
      "         0.0000,  6.0000,  0.0000]): 1\n",
      "209 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  6.9500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "210 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "211 - tensor([ 1.0000,  1.0000, 33.0000,  0.0000,  0.0000,  5.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "212 - tensor([ 3.0000,  0.0000,  9.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         1.0000,  5.0000,  0.0000]): 0\n",
      "213 - tensor([ 1.0000,  1.0000, 49.0000,  0.0000,  0.0000, 39.6000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "214 - tensor([ 2.0000,  1.0000, 54.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         4.0000,  1.0000,  0.0000]): 0\n",
      "215 - tensor([ 3.0000,  1.0000, 59.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "216 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "217 - tensor([ 3.0000,  1.0000, 26.0000,  1.0000,  2.0000, 20.5750,  2.0000, 13.3029,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "218 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 31.0000,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "219 - tensor([ 3.0000,  1.0000, 24.0000,  2.0000,  0.0000, 24.1500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "220 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  9.2167,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "221 - tensor([ 2.0000,  0.0000, 25.0000,  0.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "222 - tensor([ 2.0000,  1.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "223 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "224 - tensor([ 3.0000,  1.0000, 36.0000,  1.0000,  1.0000, 24.1500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "225 - tensor([ 1.0000,  0.0000, 51.0000,  1.0000,  0.0000, 77.9583,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "226 - tensor([ 1.0000,  1.0000, 70.0000,  1.0000,  1.0000, 71.0000,  2.0000, 87.5090,\n",
      "         4.0000,  2.0000,  0.0000]): 0\n",
      "227 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "228 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "229 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "230 - tensor([ 3.0000,  0.0000, 31.0000,  0.0000,  0.0000,  8.6833,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "231 - tensor([  1.0000,   0.0000,  31.0000,   1.0000,   0.0000, 113.2750,   0.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "232 - tensor([ 2.0000,  0.0000, 23.0000,  0.0000,  0.0000, 13.7917,  0.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "233 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 25.5875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "234 - tensor([  1.0000,   1.0000,  11.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   0.0000,   3.0000,   0.0000]): 1\n",
      "235 - tensor([  1.0000,   0.0000,  42.0000,   0.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "236 - tensor([ 1.0000,  0.0000, 19.0000,  1.0000,  0.0000, 91.0792,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "237 - tensor([ 1.0000,  1.0000, 49.0000,  1.0000,  0.0000, 89.1042,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "238 - tensor([ 1.0000,  1.0000, 45.5000,  0.0000,  0.0000, 28.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "239 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 0\n",
      "240 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "241 - tensor([ 3.0000,  1.0000, 38.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "242 - tensor([ 2.0000,  1.0000, 25.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "243 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "244 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "245 - tensor([ 3.0000,  0.0000, 27.0000,  0.0000,  2.0000, 11.1333,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "246 - tensor([ 3.0000,  0.0000, 35.0000,  1.0000,  1.0000, 20.2500,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "247 - tensor([ 1.0000,  0.0000, 49.0000,  0.0000,  0.0000, 25.9292,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "248 - tensor([ 2.0000,  1.0000,  0.8300,  0.0000,  2.0000, 29.0000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "249 - tensor([ 3.0000,  0.0000, 15.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "250 - tensor([  1.0000,   0.0000,  45.0000,   1.0000,   1.0000, 164.8667,   2.0000,\n",
      "         87.5090,   3.0000,   2.0000,   0.0000]): 1\n",
      "251 - tensor([ 3.0000,  1.0000,  3.0000,  1.0000,  1.0000, 15.9000,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "252 - tensor([ 2.0000,  0.0000, 27.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "253 - tensor([ 3.0000,  1.0000, 39.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "254 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 17.4000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "255 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  1.0000, 39.4000,  2.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "256 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 56.9292,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "257 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "258 - tensor([ 3.0000,  1.0000, 23.5000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "259 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.8000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "260 - tensor([ 2.0000,  1.0000, 54.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "261 - tensor([ 3.0000,  0.0000, 21.0000,  2.0000,  2.0000, 34.3750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "262 - tensor([ 3.0000,  1.0000, 51.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "263 - tensor([ 2.0000,  0.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "264 - tensor([ 1.0000,  0.0000, 50.0000,  0.0000,  0.0000, 28.7125,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "265 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "266 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.4333,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "267 - tensor([ 2.0000,  0.0000, 40.0000,  0.0000,  0.0000, 15.7500,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "268 - tensor([ 2.0000,  0.0000, 28.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "269 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "270 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "271 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 69.3000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "272 - tensor([  1.0000,   0.0000,  18.0000,   1.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "273 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "274 - tensor([ 2.0000,  1.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "275 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "276 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "277 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 90.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "278 - tensor([  1.0000,   0.0000,  18.0000,   2.0000,   2.0000, 262.3750,   0.0000,\n",
      "         87.5090,   1.0000,   4.0000,   0.0000]): 1\n",
      "279 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "280 - tensor([ 2.0000,  0.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "281 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  0.0000, 86.5000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "282 - tensor([ 3.0000,  1.0000, 38.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "283 - tensor([ 3.0000,  0.0000,  4.0000,  0.0000,  2.0000, 22.0250,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "284 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "285 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "286 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7875,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "287 - tensor([ 3.0000,  0.0000, 30.5000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "288 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "289 - tensor([ 3.0000,  0.0000, 43.0000,  1.0000,  6.0000, 46.9000,  2.0000, 13.3029,\n",
      "         3.0000,  7.0000,  0.0000]): 0\n",
      "290 - tensor([ 3.0000,  1.0000, 36.0000,  1.0000,  0.0000, 15.5500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "291 - tensor([ 1.0000,  1.0000, 80.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "292 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  6.9750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "293 - tensor([ 1.0000,  0.0000, 36.0000,  0.0000,  1.0000, 55.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "294 - tensor([ 3.0000,  0.0000, 11.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "295 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 30.6958,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "296 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "297 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7375,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "298 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 38.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "299 - tensor([ 1.0000,  1.0000, 71.0000,  0.0000,  0.0000, 49.5042,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "300 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "301 - tensor([ 2.0000,  1.0000, 70.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "302 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "303 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "304 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "305 - tensor([ 1.0000,  0.0000, 54.0000,  1.0000,  0.0000, 59.4000,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "306 - tensor([ 3.0000,  0.0000,  3.0000,  3.0000,  1.0000, 21.0750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "307 - tensor([  1.0000,   0.0000,  23.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   1.0000,   5.0000,   0.0000]): 1\n",
      "308 - tensor([ 3.0000,  1.0000,  1.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "309 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "310 - tensor([ 3.0000,  1.0000, 41.0000,  2.0000,  0.0000, 14.1083,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "311 - tensor([ 3.0000,  0.0000, 28.0000,  1.0000,  1.0000, 14.4000,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "312 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  4.0125,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "313 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "314 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "315 - tensor([ 3.0000,  0.0000, 25.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "316 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "317 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "318 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "319 - tensor([ 3.0000,  1.0000,  7.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "320 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8875,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "321 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "322 - tensor([ 1.0000,  1.0000, 27.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "323 - tensor([ 2.0000,  1.0000, 51.0000,  0.0000,  0.0000, 12.5250,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "324 - tensor([ 2.0000,  1.0000, 16.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "325 - tensor([ 3.0000,  1.0000, 26.0000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "326 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "327 - tensor([ 3.0000,  1.0000,  9.0000,  0.0000,  2.0000, 20.5250,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "328 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "329 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "330 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "331 - tensor([ 3.0000,  1.0000, 45.5000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "332 - tensor([ 2.0000,  0.0000, 17.0000,  0.0000,  0.0000, 12.0000,  0.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "333 - tensor([ 3.0000,  1.0000, 23.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "334 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000, 18.7875,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "335 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  0.0000,  8.8500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "336 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "337 - tensor([ 3.0000,  0.0000, 16.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         1.0000,  7.0000,  0.0000]): 0\n",
      "338 - tensor([ 3.0000,  0.0000, 16.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "339 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "340 - tensor([ 2.0000,  1.0000, 31.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "341 - tensor([ 2.0000,  0.0000, 34.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "342 - tensor([  1.0000,   0.0000,  14.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   1.0000,   3.0000,   0.0000]): 1\n",
      "343 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 31.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "344 - tensor([ 3.0000,  0.0000, 40.0000,  1.0000,  0.0000,  9.4750,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "345 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "346 - tensor([  1.0000,   0.0000,  23.0000,   1.0000,   0.0000, 113.2750,   0.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "347 - tensor([  1.0000,   0.0000,  40.0000,   1.0000,   1.0000, 134.5000,   0.0000,\n",
      "         87.5090,   3.0000,   2.0000,   0.0000]): 1\n",
      "348 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "349 - tensor([ 3.0000,  1.0000, 14.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         2.0000,  7.0000,  0.0000]): 0\n",
      "350 - tensor([ 2.0000,  0.0000, 42.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "351 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "352 - tensor([ 2.0000,  0.0000, 18.0000,  0.0000,  2.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "353 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "354 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "355 - tensor([ 2.0000,  1.0000, 59.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "356 - tensor([ 3.0000,  1.0000, 37.0000,  2.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "357 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  1.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "358 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  6.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "359 - tensor([ 3.0000,  1.0000,  1.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         0.0000,  7.0000,  0.0000]): 0\n",
      "360 - tensor([ 2.0000,  1.0000,  2.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "361 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "362 - tensor([  1.0000,   0.0000,  35.0000,   0.0000,   0.0000, 135.6333,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "363 - tensor([ 3.0000,  1.0000, 22.0000,  1.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "364 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "365 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "366 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "367 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  2.0000, 16.7000,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "368 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  6.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "369 - tensor([ 3.0000,  1.0000, 24.5000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "370 - tensor([ 2.0000,  0.0000, 57.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 0\n",
      "371 - tensor([ 2.0000,  0.0000, 55.0000,  0.0000,  0.0000, 16.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "372 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "373 - tensor([ 3.0000,  0.0000, 63.0000,  0.0000,  0.0000,  9.5875,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "374 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "375 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  0.0000,  6.4958,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "376 - tensor([ 1.0000,  0.0000, 38.0000,  1.0000,  0.0000, 71.2833,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "377 - tensor([  1.0000,   0.0000,  39.0000,   1.0000,   1.0000, 110.8833,   0.0000,\n",
      "         87.5090,   3.0000,   2.0000,   0.0000]): 1\n",
      "378 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "379 - tensor([ 2.0000,  0.0000,  4.0000,  2.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "380 - tensor([ 1.0000,  0.0000, 33.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "381 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "382 - tensor([ 1.0000,  1.0000, 52.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "383 - tensor([  1.0000,   0.0000,  36.0000,   0.0000,   0.0000, 135.6333,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "384 - tensor([  1.0000,   0.0000,  36.0000,   1.0000,   0.0000, 133.6500,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "385 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "386 - tensor([ 2.0000,  1.0000, 25.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "387 - tensor([ 2.0000,  1.0000, 19.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "388 - tensor([ 2.0000,  0.0000,  4.0000,  1.0000,  1.0000, 23.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "389 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "390 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "391 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "392 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 24.1500,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "393 - tensor([ 2.0000,  1.0000, 62.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "394 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "395 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "396 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "397 - tensor([ 1.0000,  0.0000, 39.0000,  1.0000,  0.0000, 55.9000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "398 - tensor([ 3.0000,  1.0000, 16.0000,  2.0000,  0.0000, 18.0000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "399 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  3.0000, 19.2583,  0.0000, 13.3029,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "400 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "401 - tensor([ 1.0000,  0.0000, 63.0000,  1.0000,  0.0000, 77.9583,  2.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "402 - tensor([ 1.0000,  1.0000, 31.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "403 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "404 - tensor([ 1.0000,  1.0000, 19.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "405 - tensor([ 3.0000,  0.0000, 19.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "406 - tensor([  1.0000,   0.0000,  31.0000,   0.0000,   2.0000, 164.8667,   2.0000,\n",
      "         87.5090,   1.0000,   2.0000,   0.0000]): 1\n",
      "407 - tensor([ 2.0000,  0.0000, 32.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "408 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "409 - tensor([ 3.0000,  1.0000, 74.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "410 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "411 - tensor([ 3.0000,  0.0000, 25.0000,  1.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "412 - tensor([  1.0000,   1.0000,  64.0000,   1.0000,   4.0000, 263.0000,   2.0000,\n",
      "         87.5090,   2.0000,   5.0000,   0.0000]): 0\n",
      "413 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 34.0208,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "414 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "415 - tensor([ 1.0000,  1.0000, 51.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "416 - tensor([ 1.0000,  1.0000, 31.0000,  0.0000,  0.0000, 50.4958,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "417 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 35.5000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "418 - tensor([ 2.0000,  0.0000, 30.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "419 - tensor([ 3.0000,  1.0000, 40.0000,  1.0000,  1.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "420 - tensor([ 1.0000,  0.0000, 21.0000,  0.0000,  0.0000, 77.9583,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "421 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  6.8583,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "422 - tensor([ 3.0000,  0.0000, 37.0000,  0.0000,  0.0000,  9.5875,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "423 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "424 - tensor([ 3.0000,  0.0000, 48.0000,  1.0000,  3.0000, 34.3750,  2.0000, 13.3029,\n",
      "         3.0000,  4.0000,  0.0000]): 0\n",
      "425 - tensor([ 2.0000,  1.0000, 39.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "426 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "427 - tensor([ 3.0000,  1.0000,  1.0000,  1.0000,  2.0000, 20.5750,  2.0000, 13.3029,\n",
      "         0.0000,  3.0000,  0.0000]): 1\n",
      "428 - tensor([ 3.0000,  1.0000, 45.0000,  0.0000,  0.0000,  6.9750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "429 - tensor([ 1.0000,  1.0000, 65.0000,  0.0000,  1.0000, 61.9792,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "430 - tensor([ 1.0000,  1.0000, 30.0000,  0.0000,  0.0000, 27.7500,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "431 - tensor([ 2.0000,  1.0000, 21.0000,  0.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "432 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "433 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "434 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "435 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "436 - tensor([ 1.0000,  0.0000, 19.0000,  0.0000,  2.0000, 26.2833,  2.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "437 - tensor([ 3.0000,  1.0000,  9.0000,  1.0000,  1.0000, 15.9000,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "438 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "439 - tensor([  1.0000,   1.0000,  19.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   2.0000,   5.0000,   0.0000]): 0\n",
      "440 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  2.0000, 23.4500,  2.0000, 13.3029,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "441 - tensor([ 1.0000,  1.0000, 61.0000,  0.0000,  0.0000, 33.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "442 - tensor([ 2.0000,  1.0000, 42.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "443 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  1.0000,  9.3500,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "444 - tensor([ 3.0000,  1.0000, 20.5000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "445 - tensor([ 3.0000,  0.0000, 30.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "446 - tensor([ 2.0000,  1.0000, 36.0000,  0.0000,  0.0000, 12.8750,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "447 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 29.7000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "448 - tensor([ 3.0000,  0.0000,  1.0000,  1.0000,  1.0000, 11.1333,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "449 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "450 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "451 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "452 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "453 - tensor([ 1.0000,  1.0000, 48.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "454 - tensor([ 1.0000,  0.0000, 52.0000,  1.0000,  1.0000, 93.5000,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "455 - tensor([ 1.0000,  1.0000, 42.0000,  1.0000,  0.0000, 52.5542,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "456 - tensor([ 1.0000,  1.0000, 58.0000,  0.0000,  0.0000, 29.7000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "457 - tensor([  1.0000,   1.0000,  29.0000,   0.0000,   0.0000, 221.7792,   2.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 0\n",
      "458 - tensor([ 3.0000,  1.0000, 28.5000,  0.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "459 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "460 - tensor([ 3.0000,  0.0000, 14.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "461 - tensor([ 1.0000,  0.0000, 22.0000,  0.0000,  2.0000, 49.5000,  0.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "462 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "463 - tensor([ 3.0000,  1.0000, 16.0000,  1.0000,  3.0000, 34.3750,  2.0000, 13.3029,\n",
      "         2.0000,  4.0000,  0.0000]): 0\n",
      "464 - tensor([ 2.0000,  0.0000, 19.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "465 - tensor([ 3.0000,  1.0000,  6.0000,  0.0000,  1.0000, 12.4750,  2.0000, 13.3029,\n",
      "         0.0000,  1.0000,  0.0000]): 1\n",
      "466 - tensor([ 3.0000,  0.0000, 31.0000,  1.0000,  1.0000, 20.5250,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "467 - tensor([ 2.0000,  1.0000, 27.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "468 - tensor([ 3.0000,  0.0000, 14.0000,  1.0000,  0.0000, 11.2417,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "469 - tensor([ 3.0000,  0.0000, 20.0000,  1.0000,  0.0000,  9.8250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "470 - tensor([ 2.0000,  0.0000, 22.0000,  1.0000,  1.0000, 29.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "471 - tensor([ 3.0000,  0.0000, 22.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "472 - tensor([ 3.0000,  1.0000, 11.0000,  0.0000,  0.0000, 18.7875,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "473 - tensor([ 1.0000,  1.0000, 46.0000,  1.0000,  0.0000, 61.1750,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "474 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "475 - tensor([ 2.0000,  1.0000, 39.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "476 - tensor([ 1.0000,  0.0000, 39.0000,  1.0000,  1.0000, 79.6500,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "477 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "478 - tensor([ 3.0000,  1.0000,  9.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         0.0000,  7.0000,  0.0000]): 0\n",
      "479 - tensor([  1.0000,   1.0000,  38.0000,   0.0000,   1.0000, 153.4625,   2.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "480 - tensor([  1.0000,   1.0000,  58.0000,   0.0000,   2.0000, 113.2750,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "481 - tensor([ 1.0000,  1.0000, 52.0000,  1.0000,  1.0000, 79.6500,  2.0000, 87.5090,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "482 - tensor([ 2.0000,  0.0000,  7.0000,  0.0000,  2.0000, 26.2500,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "483 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 24.1500,  1.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "484 - tensor([ 3.0000,  1.0000, 65.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "485 - tensor([ 2.0000,  0.0000,  2.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "486 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "487 - tensor([ 2.0000,  0.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "488 - tensor([ 3.0000,  1.0000, 16.0000,  1.0000,  1.0000, 20.2500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "489 - tensor([ 2.0000,  0.0000, 34.0000,  0.0000,  1.0000, 23.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "490 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "491 - tensor([ 3.0000,  1.0000, 11.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         0.0000,  7.0000,  0.0000]): 0\n",
      "492 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "493 - tensor([  1.0000,   1.0000,  17.0000,   0.0000,   2.0000, 110.8833,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 1\n",
      "494 - tensor([ 1.0000,  0.0000, 48.0000,  0.0000,  0.0000, 25.9292,  2.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "495 - tensor([ 2.0000,  1.0000, 18.0000,  0.0000,  0.0000, 11.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "496 - tensor([ 2.0000,  0.0000, 40.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "497 - tensor([ 3.0000,  0.0000, 18.0000,  2.0000,  0.0000, 18.0000,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "498 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 15.0500,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "499 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "500 - tensor([ 1.0000,  0.0000, 49.0000,  1.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "501 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "502 - tensor([ 3.0000,  1.0000,  4.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         0.0000, 10.0000,  0.0000]): 0\n",
      "503 - tensor([ 2.0000,  0.0000, 36.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "504 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "505 - tensor([ 3.0000,  0.0000, 21.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "506 - tensor([ 2.0000,  1.0000, 18.0000,  0.0000,  0.0000, 11.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "507 - tensor([ 1.0000,  1.0000, 23.0000,  0.0000,  1.0000, 63.3583,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "508 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "509 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "510 - tensor([ 2.0000,  1.0000, 42.0000,  1.0000,  0.0000, 27.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "511 - tensor([ 1.0000,  1.0000, 65.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "512 - tensor([ 3.0000,  1.0000, 34.0000,  1.0000,  1.0000, 14.4000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "513 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "514 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000, 10.5167,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "515 - tensor([  1.0000,   0.0000,   2.0000,   1.0000,   2.0000, 151.5500,   2.0000,\n",
      "         87.5090,   1.0000,   3.0000,   0.0000]): 0\n",
      "516 - tensor([ 2.0000,  0.0000, 50.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "517 - tensor([ 1.0000,  1.0000, 25.0000,  1.0000,  0.0000, 91.0792,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "518 - tensor([ 2.0000,  0.0000, 41.0000,  0.0000,  1.0000, 19.5000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "519 - tensor([ 2.0000,  0.0000, 19.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "520 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  9.4833,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "521 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "522 - tensor([ 3.0000,  0.0000, 32.0000,  1.0000,  1.0000, 15.5000,  1.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "523 - tensor([ 1.0000,  1.0000, 27.0000,  0.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "524 - tensor([ 1.0000,  0.0000, 39.0000,  1.0000,  1.0000, 83.1583,  0.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "525 - tensor([ 3.0000,  1.0000, 36.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "526 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "527 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "528 - tensor([ 2.0000,  0.0000, 35.0000,  0.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "529 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 26.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "530 - tensor([ 3.0000,  0.0000,  1.0000,  0.0000,  2.0000, 15.7417,  0.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "531 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "532 - tensor([ 2.0000,  1.0000, 48.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "533 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "534 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "535 - tensor([ 1.0000,  0.0000, 19.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "536 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "537 - tensor([ 3.0000,  0.0000, 29.0000,  1.0000,  1.0000, 10.4625,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "538 - tensor([ 1.0000,  0.0000, 18.0000,  0.0000,  2.0000, 79.6500,  2.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "539 - tensor([ 1.0000,  1.0000, 49.0000,  1.0000,  0.0000, 56.9292,  0.0000, 87.5090,\n",
      "         4.0000,  1.0000,  0.0000]): 1\n",
      "540 - tensor([ 2.0000,  0.0000, 14.0000,  1.0000,  0.0000, 30.0708,  0.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "541 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  2.0000, 14.5000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "542 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  8.3625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "543 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "544 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 83.4750,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "545 - tensor([  1.0000,   1.0000,  49.0000,   1.0000,   1.0000, 110.8833,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "546 - tensor([ 3.0000,  0.0000, 17.0000,  0.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "547 - tensor([ 2.0000,  1.0000, 44.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "548 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 19.9667,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "549 - tensor([ 1.0000,  1.0000, 44.0000,  2.0000,  0.0000, 90.0000,  1.0000, 87.5090,\n",
      "         4.0000,  2.0000,  0.0000]): 0\n",
      "550 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "551 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "552 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7375,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "553 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "554 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "555 - tensor([  1.0000,   0.0000,  22.0000,   0.0000,   0.0000, 151.5500,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "556 - tensor([ 3.0000,  1.0000, 51.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "557 - tensor([ 3.0000,  1.0000, 17.0000,  1.0000,  1.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "558 - tensor([ 2.0000,  0.0000, 24.0000,  2.0000,  3.0000, 18.7500,  2.0000, 21.1792,\n",
      "         3.0000,  5.0000,  0.0000]): 1\n",
      "559 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  9.8458,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "560 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "561 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "562 - tensor([ 1.0000,  1.0000, 28.0000,  1.0000,  0.0000, 82.1708,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "563 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "564 - tensor([ 2.0000,  1.0000, 25.0000,  1.0000,  2.0000, 41.5792,  0.0000, 21.1792,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "565 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "566 - tensor([ 2.0000,  1.0000, 33.0000,  0.0000,  0.0000, 12.2750,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "567 - tensor([ 1.0000,  1.0000, 37.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "568 - tensor([ 3.0000,  0.0000, 15.0000,  0.0000,  0.0000,  8.0292,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "569 - tensor([ 1.0000,  1.0000, 55.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "570 - tensor([ 1.0000,  1.0000, 64.0000,  0.0000,  0.0000, 26.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "571 - tensor([ 3.0000,  0.0000, 22.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "572 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 35.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "573 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "574 - tensor([ 3.0000,  1.0000, 29.0000,  2.0000,  0.0000, 23.2500,  1.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "575 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "576 - tensor([ 1.0000,  0.0000, 17.0000,  1.0000,  0.0000, 57.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "577 - tensor([ 3.0000,  0.0000, 39.0000,  1.0000,  5.0000, 31.2750,  2.0000, 13.3029,\n",
      "         3.0000,  6.0000,  0.0000]): 0\n",
      "578 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "579 - tensor([  1.0000,   0.0000,  21.0000,   2.0000,   2.0000, 262.3750,   0.0000,\n",
      "         87.5090,   1.0000,   4.0000,   0.0000]): 1\n",
      "580 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  8.6625,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "581 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "582 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "583 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "584 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "585 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "586 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "587 - tensor([ 1.0000,  0.0000, 22.0000,  1.0000,  0.0000, 66.6000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "588 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "589 - tensor([  1.0000,   0.0000,  36.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   3.0000,   3.0000,   0.0000]): 1\n",
      "590 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "591 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 93.5000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "592 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.6958,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "593 - tensor([  1.0000,   0.0000,  38.0000,   0.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "594 - tensor([ 3.0000,  0.0000, 39.0000,  0.0000,  5.0000, 29.1250,  1.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "595 - tensor([ 2.0000,  0.0000, 48.0000,  1.0000,  2.0000, 65.0000,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "596 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "597 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "598 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "599 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "600 - tensor([ 1.0000,  0.0000, 48.0000,  1.0000,  0.0000, 39.6000,  0.0000, 87.5090,\n",
      "         4.0000,  1.0000,  0.0000]): 1\n",
      "601 - tensor([ 3.0000,  0.0000, 24.0000,  1.0000,  0.0000, 15.8500,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "602 - tensor([ 1.0000,  1.0000, 38.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "603 - tensor([  1.0000,   1.0000,  35.0000,   0.0000,   0.0000, 512.3292,   0.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 1\n",
      "604 - tensor([ 1.0000,  1.0000, 28.0000,  0.0000,  0.0000, 47.1000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "605 - tensor([ 3.0000,  0.0000, 29.0000,  0.0000,  4.0000, 21.0750,  2.0000, 13.3029,\n",
      "         3.0000,  4.0000,  0.0000]): 0\n",
      "606 - tensor([ 2.0000,  0.0000,  5.0000,  1.0000,  2.0000, 27.7500,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "607 - tensor([ 3.0000,  1.0000, 41.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "608 - tensor([ 2.0000,  1.0000, 27.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "609 - tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         0.0000,  4.0000,  0.0000]): 0\n",
      "610 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "611 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "612 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "613 - tensor([  1.0000,   0.0000,  36.0000,   1.0000,   0.0000, 146.5208,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "614 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "615 - tensor([ 3.0000,  1.0000, 12.0000,  1.0000,  0.0000, 11.2417,  0.0000, 13.3029,\n",
      "         0.0000,  1.0000,  0.0000]): 1\n",
      "616 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  1.0000, 20.2125,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "617 - tensor([ 3.0000,  1.0000, 30.5000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "618 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "619 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000, 22.5250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "620 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "621 - tensor([ 2.0000,  1.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "622 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "623 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "624 - tensor([ 3.0000,  0.0000, 21.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "625 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "626 - tensor([ 2.0000,  1.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "627 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 25.9250,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "628 - tensor([ 3.0000,  1.0000, 49.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "629 - tensor([ 1.0000,  1.0000, 26.0000,  0.0000,  0.0000, 30.0000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "630 - tensor([ 2.0000,  0.0000, 18.0000,  0.0000,  1.0000, 23.0000,  2.0000, 21.1792,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "631 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "632 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "633 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "634 - tensor([ 3.0000,  1.0000, 39.0000,  1.0000,  5.0000, 31.2750,  2.0000, 13.3029,\n",
      "         2.0000,  6.0000,  0.0000]): 0\n",
      "635 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "636 - tensor([ 3.0000,  0.0000, 22.0000,  2.0000,  0.0000, 23.2500,  1.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "637 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "638 - tensor([ 2.0000,  1.0000, 19.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "639 - tensor([ 2.0000,  1.0000, 31.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "640 - tensor([ 3.0000,  0.0000, 21.0000,  1.0000,  0.0000,  9.8250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "641 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "642 - tensor([ 3.0000,  1.0000, 29.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         2.0000, 10.0000,  0.0000]): 0\n",
      "643 - tensor([ 3.0000,  0.0000, 14.5000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "644 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "645 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "646 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "647 - tensor([  1.0000,   1.0000,  36.0000,   0.0000,   1.0000, 512.3292,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 1\n",
      "648 - tensor([ 2.0000,  0.0000, 42.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "649 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "650 - tensor([ 3.0000,  1.0000, 28.0000,  2.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "651 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "652 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 82.1708,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "653 - tensor([ 3.0000,  0.0000,  5.0000,  0.0000,  0.0000, 12.4750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "654 - tensor([ 1.0000,  0.0000, 53.0000,  2.0000,  0.0000, 51.4792,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "655 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "656 - tensor([ 2.0000,  1.0000, 31.0000,  1.0000,  1.0000, 37.0042,  0.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "657 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "658 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 86.5000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "659 - tensor([ 1.0000,  1.0000, 60.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "660 - tensor([ 3.0000,  1.0000, 29.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         2.0000, 10.0000,  0.0000]): 0\n",
      "661 - tensor([ 1.0000,  0.0000, 47.0000,  1.0000,  1.0000, 52.5542,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "662 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "663 - tensor([ 1.0000,  0.0000, 38.0000,  0.0000,  0.0000, 80.0000,  3.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "664 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "665 - tensor([ 3.0000,  1.0000, 47.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "666 - tensor([ 3.0000,  1.0000,  2.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "667 - tensor([ 1.0000,  0.0000, 36.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "668 - tensor([  1.0000,   0.0000,  35.0000,   0.0000,   0.0000, 512.3292,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "669 - tensor([ 3.0000,  1.0000, 48.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "670 - tensor([ 3.0000,  0.0000, 29.0000,  0.0000,  2.0000, 15.2458,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "671 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "672 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "673 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000, 10.1708,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "674 - tensor([ 1.0000,  0.0000, 36.0000,  0.0000,  2.0000, 71.0000,  2.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "675 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  1.0000, 57.9792,  0.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "676 - tensor([ 3.0000,  1.0000, 43.0000,  0.0000,  0.0000,  6.4500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "677 - tensor([ 3.0000,  1.0000, 36.0000,  0.0000,  0.0000,  7.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "678 - tensor([ 2.0000,  1.0000, 35.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "679 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "680 - tensor([ 3.0000,  0.0000,  0.7500,  2.0000,  1.0000, 19.2583,  0.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "681 - tensor([ 2.0000,  0.0000, 45.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "682 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "683 - tensor([ 3.0000,  1.0000, 26.0000,  1.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "684 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "685 - tensor([ 2.0000,  0.0000, 22.0000,  0.0000,  0.0000, 33.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "686 - tensor([ 1.0000,  0.0000, 52.0000,  1.0000,  0.0000, 78.2667,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "687 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "688 - tensor([ 1.0000,  1.0000, 40.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "689 - tensor([ 1.0000,  1.0000, 62.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "690 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "691 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "692 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "693 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "694 - tensor([ 3.0000,  1.0000, 43.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "695 - tensor([ 3.0000,  0.0000,  9.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "696 - tensor([ 3.0000,  1.0000,  9.0000,  4.0000,  2.0000, 31.3875,  2.0000, 13.3029,\n",
      "         0.0000,  6.0000,  0.0000]): 0\n",
      "697 - tensor([ 1.0000,  1.0000, 37.0000,  0.0000,  1.0000, 29.7000,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "698 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "699 - tensor([ 1.0000,  0.0000, 60.0000,  1.0000,  0.0000, 75.2500,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "700 - tensor([ 3.0000,  1.0000, 50.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "701 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "702 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "703 - tensor([ 3.0000,  1.0000, 32.0000,  1.0000,  0.0000, 15.8500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "704 - tensor([ 3.0000,  0.0000, 41.0000,  0.0000,  2.0000, 20.2125,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "705 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  7.4958,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "706 - tensor([ 2.0000,  0.0000, 22.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "707 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "708 - tensor([ 3.0000,  0.0000, 27.0000,  0.0000,  1.0000, 12.4750,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "709 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  9.3500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "710 - tensor([ 3.0000,  0.0000,  5.0000,  2.0000,  1.0000, 19.2583,  0.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "711 - tensor([ 1.0000,  1.0000, 34.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "712 - tensor([ 1.0000,  1.0000, 29.0000,  1.0000,  0.0000, 66.6000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "################################################## 2\n",
      "[TRAIN]\n",
      "0 - torch.Size([16, 11]): torch.Size([16])\n",
      "1 - torch.Size([16, 11]): torch.Size([16])\n",
      "2 - torch.Size([16, 11]): torch.Size([16])\n",
      "3 - torch.Size([16, 11]): torch.Size([16])\n",
      "4 - torch.Size([16, 11]): torch.Size([16])\n",
      "5 - torch.Size([16, 11]): torch.Size([16])\n",
      "6 - torch.Size([16, 11]): torch.Size([16])\n",
      "7 - torch.Size([16, 11]): torch.Size([16])\n",
      "8 - torch.Size([16, 11]): torch.Size([16])\n",
      "9 - torch.Size([16, 11]): torch.Size([16])\n",
      "10 - torch.Size([16, 11]): torch.Size([16])\n",
      "11 - torch.Size([16, 11]): torch.Size([16])\n",
      "12 - torch.Size([16, 11]): torch.Size([16])\n",
      "13 - torch.Size([16, 11]): torch.Size([16])\n",
      "14 - torch.Size([16, 11]): torch.Size([16])\n",
      "15 - torch.Size([16, 11]): torch.Size([16])\n",
      "16 - torch.Size([16, 11]): torch.Size([16])\n",
      "17 - torch.Size([16, 11]): torch.Size([16])\n",
      "18 - torch.Size([16, 11]): torch.Size([16])\n",
      "19 - torch.Size([16, 11]): torch.Size([16])\n",
      "20 - torch.Size([16, 11]): torch.Size([16])\n",
      "21 - torch.Size([16, 11]): torch.Size([16])\n",
      "22 - torch.Size([16, 11]): torch.Size([16])\n",
      "23 - torch.Size([16, 11]): torch.Size([16])\n",
      "24 - torch.Size([16, 11]): torch.Size([16])\n",
      "25 - torch.Size([16, 11]): torch.Size([16])\n",
      "26 - torch.Size([16, 11]): torch.Size([16])\n",
      "27 - torch.Size([16, 11]): torch.Size([16])\n",
      "28 - torch.Size([16, 11]): torch.Size([16])\n",
      "29 - torch.Size([16, 11]): torch.Size([16])\n",
      "30 - torch.Size([16, 11]): torch.Size([16])\n",
      "31 - torch.Size([16, 11]): torch.Size([16])\n",
      "32 - torch.Size([16, 11]): torch.Size([16])\n",
      "33 - torch.Size([16, 11]): torch.Size([16])\n",
      "34 - torch.Size([16, 11]): torch.Size([16])\n",
      "35 - torch.Size([16, 11]): torch.Size([16])\n",
      "36 - torch.Size([16, 11]): torch.Size([16])\n",
      "37 - torch.Size([16, 11]): torch.Size([16])\n",
      "38 - torch.Size([16, 11]): torch.Size([16])\n",
      "39 - torch.Size([16, 11]): torch.Size([16])\n",
      "40 - torch.Size([16, 11]): torch.Size([16])\n",
      "41 - torch.Size([16, 11]): torch.Size([16])\n",
      "42 - torch.Size([16, 11]): torch.Size([16])\n",
      "43 - torch.Size([16, 11]): torch.Size([16])\n",
      "44 - torch.Size([9, 11]): torch.Size([9])\n",
      "[VALIDATION]\n",
      "0 - torch.Size([16, 11]): torch.Size([16])\n",
      "1 - torch.Size([16, 11]): torch.Size([16])\n",
      "2 - torch.Size([16, 11]): torch.Size([16])\n",
      "3 - torch.Size([16, 11]): torch.Size([16])\n",
      "4 - torch.Size([16, 11]): torch.Size([16])\n",
      "5 - torch.Size([16, 11]): torch.Size([16])\n",
      "6 - torch.Size([16, 11]): torch.Size([16])\n",
      "7 - torch.Size([16, 11]): torch.Size([16])\n",
      "8 - torch.Size([16, 11]): torch.Size([16])\n",
      "9 - torch.Size([16, 11]): torch.Size([16])\n",
      "10 - torch.Size([16, 11]): torch.Size([16])\n",
      "11 - torch.Size([2, 11]): torch.Size([2])\n",
      "################################################## 3\n",
      "[TEST]\n",
      "torch.Size([418, 11])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": # 실행\n",
    "  train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "  print(\"train_dataset: {0}, validation_dataset.shape: {1}, test_dataset: {2}\".format(\n",
    "    len(train_dataset), len(validation_dataset), len(test_dataset)\n",
    "  ))\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  for idx, sample in enumerate(train_dataset):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, sample['input'], sample['target']))\n",
    "\n",
    "  print(\"#\" * 50, 2)\n",
    "  # 잘 만들어진 데이터를 load\n",
    "  train_data_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=16, shuffle=True)\n",
    "  test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "  print(\"[TRAIN]\")\n",
    "  for idx, batch in enumerate(train_data_loader):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "  print(\"[VALIDATION]\")\n",
    "  for idx, batch in enumerate(validation_data_loader):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "  print(\"#\" * 50, 3)\n",
    "\n",
    "  test(test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[요구사항 2]\n",
    "----\n",
    "titanic 딥러닝 모델 훈련 코드 및 activation function 변경해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            #wandb.config.n_hidden_unit_list[0] 에서 설정된 첫 번째 히든레이어 노드 수\n",
    "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_and_optimizer():\n",
    "    my_model = MyModel(n_input=11, n_output=2)\n",
    "\n",
    "    #스토캐스틱 그라디언트 디센트로 모델 학습, 러닝 레이트는 wandb.config.learning_rate\n",
    "    optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "    return my_model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "    n_epochs = wandb.config.epochs # 반복 횟수\n",
    "    loss_fn = nn.CrossEntropyLoss()  # 이진 분류 문제이므로 CrossEntropyLoss 사용\n",
    "    next_print_epoch = 100 # 100번마다 loss 출력\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        num_trains = 0\n",
    "        for train_batch in train_data_loader:\n",
    "            #target을 예측하는 학습 수행\n",
    "            input, target = train_batch['input'], train_batch['target']\n",
    "            output_train = model(input)\n",
    "            #loss 계산\n",
    "            loss = loss_fn(output_train, target)\n",
    "            loss_train += loss.item()\n",
    "            num_trains += 1\n",
    "\n",
    "            #그라디언트 초기화, 그라디언트가 초기화를 자동으로 안해줌\n",
    "            optimizer.zero_grad()\n",
    "            # 그라디언트 계산\n",
    "            loss.backward()\n",
    "            #SGD\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_validation = 0.0\n",
    "        num_validations = 0\n",
    "\n",
    "        #computation graph x\n",
    "        #validation 계산, train과 동일한 알고리즘이지만 업데이트는 하지 않음.\n",
    "        with torch.no_grad():\n",
    "            for validation_batch in validation_data_loader:\n",
    "                input, target = validation_batch['input'], validation_batch['target']\n",
    "                output_validation = model(input)\n",
    "                loss = loss_fn(output_validation, target)\n",
    "                loss_validation += loss.item()\n",
    "                num_validations += 1\n",
    "\n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch,\n",
    "            \"Training loss\": loss_train / num_trains,\n",
    "            \"Validation loss\": loss_validation / num_validations\n",
    "        })\n",
    "        #100회마다 진행\n",
    "        if epoch >= next_print_epoch:\n",
    "            print(\n",
    "                f\"Epoch {epoch}, \"\n",
    "                f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "                f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "            )\n",
    "            next_print_epoch += 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 test 하고 submission 생성\n",
    "\n",
    "def test_and_create_submission(model, test_data_loader):\n",
    "    model.eval()  # 모델을 평가 모드로 전환, 가중치를 업데이트 하지 않음\n",
    "    all_predictions = []\n",
    "    passenger_ids = list(range(892, 892 + len(test_data_loader.dataset)))  # Titanic 테스트 데이터의 승객 ID는 892부터 시작\n",
    "\n",
    "    #업데이트를 하지 않기 때문에 no_grad\n",
    "    with torch.no_grad():\n",
    "        for test_batch in test_data_loader:\n",
    "            input = test_batch['input']  # TitanicTestDataset을 사용하여 'input' 데이터를 가져옴\n",
    "            output = model(input)\n",
    "            predictions = torch.argmax(output, dim=1).cpu().numpy()  # 0 or 1 중 가장 높은 확률의 클래스를 예측\n",
    "            all_predictions.extend(predictions)\n",
    "\n",
    "    # submission.csv 생성\n",
    "    submission_df = pd.DataFrame({\n",
    "        #형식에 맞게\n",
    "        'PassengerId': passenger_ids,\n",
    "        'Survived': all_predictions\n",
    "    })\n",
    "    \n",
    "    submission_df.to_csv('submission_test.csv', index=False)\n",
    "    print(\"submission_test.csv 파일이 생성되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    #현재 시간 기록\n",
    "    current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    #모델에 설정할 값들을 담은 딕셔너리\n",
    "    #에포크, 배치사이즈, 러닝 레이트, 히든 유닛 개수 등 포함되어 있음\n",
    "    config = {\n",
    "        'epochs': args.epochs,\n",
    "        'batch_size': args.batch_size,\n",
    "        'learning_rate': 1e-3,\n",
    "        'n_hidden_unit_list': [20, 20],\n",
    "    }\n",
    "\n",
    "    #wandb 모델의 초기값 생성\n",
    "    wandb.init(\n",
    "        mode=\"online\" if args.wandb else \"disabled\",\n",
    "        project=\"my_model_training\",\n",
    "        notes=\"Titanic Dataset experiment\",\n",
    "        tags=[\"my_model\", \"titanic\"],\n",
    "        name=current_time_str,\n",
    "        config=config\n",
    "    )\n",
    "    print(args)\n",
    "    print(wandb.config)\n",
    "\n",
    "    #모델과 옵티마이저 생성\n",
    "    model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "    print(\"#\" * 50, 1)\n",
    "\n",
    "    #모델 train 시작.\n",
    "    training_loop(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        train_data_loader=train_data_loader,\n",
    "        validation_data_loader=validation_data_loader\n",
    "    )\n",
    "    #train 끝\n",
    "    #test 실행\n",
    "    test_and_create_submission(model, test_data_loader)\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33majhajh503\u001b[0m (\u001b[33majhajh503-korea-university-of-technology-and-education\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ajhaj\\git\\link_dl\\_04_homeworks_solution\\homework_2\\wandb\\run-20241018_024229-n0gp774x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/n0gp774x' target=\"_blank\">2024-10-18_02-42-29</a></strong> to <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/n0gp774x' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/n0gp774x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x000001DB6D7057E0>\n",
      "{'epochs': 2000, 'batch_size': 512, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20]}\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5617, Validation loss 0.5655\n",
      "Epoch 200, Training loss 0.5521, Validation loss 0.5916\n",
      "Epoch 300, Training loss 0.5294, Validation loss 0.5316\n",
      "Epoch 400, Training loss 0.5060, Validation loss 0.5474\n",
      "Epoch 500, Training loss 0.4754, Validation loss 0.5379\n",
      "Epoch 600, Training loss 0.4517, Validation loss 0.4871\n",
      "Epoch 700, Training loss 0.4382, Validation loss 0.5334\n",
      "Epoch 800, Training loss 0.4189, Validation loss 0.4767\n",
      "Epoch 900, Training loss 0.4232, Validation loss 0.4773\n",
      "Epoch 1000, Training loss 0.4232, Validation loss 0.4789\n",
      "Epoch 1100, Training loss 0.4054, Validation loss 0.5427\n",
      "Epoch 1200, Training loss 0.4059, Validation loss 0.5976\n",
      "Epoch 1300, Training loss 0.4005, Validation loss 0.4707\n",
      "Epoch 1400, Training loss 0.3926, Validation loss 0.4882\n",
      "Epoch 1500, Training loss 0.3907, Validation loss 0.5508\n",
      "Epoch 1600, Training loss 0.3816, Validation loss 0.5261\n",
      "Epoch 1700, Training loss 0.4006, Validation loss 0.4712\n",
      "Epoch 1800, Training loss 0.3763, Validation loss 0.4840\n",
      "Epoch 1900, Training loss 0.3829, Validation loss 0.4677\n",
      "Epoch 2000, Training loss 0.3881, Validation loss 0.6080\n",
      "submission_test.csv 파일이 생성되었습니다!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▁▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>Training loss</td><td>█████▇▇▇▆▆▅▄▄▃▃▃▃▃▃▃▂▃▃▃▂▃▂▂▃▂▂▂▂▁▂▂▁▁▂▁</td></tr><tr><td>Validation loss</td><td>▅▅▆▅▄▅▅▂▃▄▄▂▃▃▂▁▂▁▂▃▇▃▂▁▁▂▁▂▂▁▅▃▂▄▂▃▃▁▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>2000</td></tr><tr><td>Training loss</td><td>0.38812</td></tr><tr><td>Validation loss</td><td>0.608</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-10-18_02-42-29</strong> at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/n0gp774x' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/n0gp774x</a><br/> View project at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241018_024229-n0gp774x\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Jupyter Notebook 환경을 확인하여 argparse를 우회.\n",
    "    if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "        # 기본값을 설정\n",
    "        class Args:\n",
    "            wandb = True\n",
    "            batch_size = 512\n",
    "            epochs = 2000 # Early stopping을 위해 epochs를 2000으로 설정\n",
    "\n",
    "        args = Args() # args 추가\n",
    "        main(args) # 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu 활성화 함수\n",
    "---\n",
    "https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/77qgbsbu?nw=nwuserajhajh503\n",
    "\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/Relu_training_loss.svg)\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/Relu_V.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ajhaj\\git\\link_dl\\_04_homeworks_solution\\homework_2\\wandb\\run-20241018_024408-qv4ha66j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/qv4ha66j' target=\"_blank\">2024-10-18_02-44-08</a></strong> to <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/qv4ha66j' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/qv4ha66j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x000001DB71404D30>\n",
      "{'epochs': 2000, 'batch_size': 512, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20]}\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5589, Validation loss 0.5985\n",
      "Epoch 200, Training loss 0.5267, Validation loss 0.5495\n",
      "Epoch 300, Training loss 0.4993, Validation loss 0.6037\n",
      "Epoch 400, Training loss 0.4664, Validation loss 0.5006\n",
      "Epoch 500, Training loss 0.4634, Validation loss 0.5793\n",
      "Epoch 600, Training loss 0.4379, Validation loss 0.5993\n",
      "Epoch 700, Training loss 0.4257, Validation loss 0.5441\n",
      "Epoch 800, Training loss 0.4109, Validation loss 0.5218\n",
      "Epoch 900, Training loss 0.4007, Validation loss 0.4736\n",
      "Epoch 1000, Training loss 0.3959, Validation loss 0.5473\n",
      "Epoch 1100, Training loss 0.3990, Validation loss 0.4739\n",
      "Epoch 1200, Training loss 0.4033, Validation loss 0.5078\n",
      "Epoch 1300, Training loss 0.3954, Validation loss 0.4806\n",
      "Epoch 1400, Training loss 0.3860, Validation loss 0.5268\n",
      "Epoch 1500, Training loss 0.3813, Validation loss 0.5453\n",
      "Epoch 1600, Training loss 0.3645, Validation loss 0.5358\n",
      "Epoch 1700, Training loss 0.3823, Validation loss 0.5935\n",
      "Epoch 1800, Training loss 0.3737, Validation loss 0.5433\n",
      "Epoch 1900, Training loss 0.3555, Validation loss 0.5661\n",
      "Epoch 2000, Training loss 0.3629, Validation loss 0.5622\n",
      "submission_test.csv 파일이 생성되었습니다!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇████</td></tr><tr><td>Training loss</td><td>█▇▇▄▄▅▄▄▃▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation loss</td><td>▄▄▃▄▃▃▄▃▁▃▂▂▂▅▂▂▇▂▁▁▄▁▂▅▁▁▂▂▂▅▃▄▃▁▁▁█▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>2000</td></tr><tr><td>Training loss</td><td>0.36293</td></tr><tr><td>Validation loss</td><td>0.56218</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-10-18_02-44-08</strong> at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/qv4ha66j' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/qv4ha66j</a><br/> View project at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241018_024408-qv4ha66j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ELU로 변경, 그외 전부 동일\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            #wandb.config.n_hidden_unit_list[0] 에서 설정된 첫 번째 히든레이어 노드 수\n",
    "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter Notebook 환경을 확인하여 argparse를 우회.\n",
    "    if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "        # 기본값을 설정\n",
    "        class Args:\n",
    "            wandb = True\n",
    "            batch_size = 512\n",
    "            epochs = 2000 # Early stopping을 위해 epochs를 2000으로 설정\n",
    "\n",
    "        args = Args() # args 추가\n",
    "        main(args) # 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELU 활성화 함수\n",
    "---\n",
    "https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/qazpje1y?nw=nwuserajhajh503\n",
    "\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/ELU_T.svg)\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/ELU_V.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ajhaj\\git\\link_dl\\_04_homeworks_solution\\homework_2\\wandb\\run-20241018_024544-47e300cq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/47e300cq' target=\"_blank\">2024-10-18_02-45-44</a></strong> to <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/47e300cq' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/47e300cq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x000001DB71407F40>\n",
      "{'epochs': 2000, 'batch_size': 512, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20]}\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5718, Validation loss 0.5917\n",
      "Epoch 200, Training loss 0.5533, Validation loss 0.6267\n",
      "Epoch 300, Training loss 0.5342, Validation loss 0.5681\n",
      "Epoch 400, Training loss 0.4921, Validation loss 0.5394\n",
      "Epoch 500, Training loss 0.4626, Validation loss 0.5517\n",
      "Epoch 600, Training loss 0.4328, Validation loss 0.6449\n",
      "Epoch 700, Training loss 0.4255, Validation loss 0.4834\n",
      "Epoch 800, Training loss 0.4306, Validation loss 0.5361\n",
      "Epoch 900, Training loss 0.4231, Validation loss 0.4775\n",
      "Epoch 1000, Training loss 0.4020, Validation loss 0.5486\n",
      "Epoch 1100, Training loss 0.3912, Validation loss 0.6462\n",
      "Epoch 1200, Training loss 0.4127, Validation loss 0.6023\n",
      "Epoch 1300, Training loss 0.4005, Validation loss 0.5501\n",
      "Epoch 1400, Training loss 0.4035, Validation loss 0.8314\n",
      "Epoch 1500, Training loss 0.3953, Validation loss 0.4848\n",
      "Epoch 1600, Training loss 0.3819, Validation loss 0.5396\n",
      "Epoch 1700, Training loss 0.4032, Validation loss 0.4828\n",
      "Epoch 1800, Training loss 0.3887, Validation loss 0.5181\n",
      "Epoch 1900, Training loss 0.3711, Validation loss 0.5947\n",
      "Epoch 2000, Training loss 0.3702, Validation loss 0.6703\n",
      "submission_test.csv 파일이 생성되었습니다!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇████</td></tr><tr><td>Training loss</td><td>███▇▇▇▆▆▆▆▅▅▅▄▄▃▃▄▃▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation loss</td><td>▄▄▅▄▄▄▃█▄▂▂▂▃▃▁▃▃▃▁▂▂▂▆▂▂▂▅▃▂▂▁▁▂▁▁▃▁▄▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>2000</td></tr><tr><td>Training loss</td><td>0.37016</td></tr><tr><td>Validation loss</td><td>0.67026</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-10-18_02-45-44</strong> at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/47e300cq' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/47e300cq</a><br/> View project at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241018_024544-47e300cq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LeakyReLU로 변경, 그외 전부 동일\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            #wandb.config.n_hidden_unit_list[0] 에서 설정된 첫 번째 히든레이어 노드 수\n",
    "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter Notebook 환경을 확인하여 argparse를 우회.\n",
    "    if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "        # 기본값을 설정\n",
    "        class Args:\n",
    "            wandb = True\n",
    "            batch_size = 512\n",
    "            epochs = 2000 # Early stopping을 위해 epochs를 2000으로 설정\n",
    "\n",
    "        args = Args() # args 추가\n",
    "        main(args) # 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeakyReLU 활성화 함수\n",
    "---\n",
    "https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/vzofv6wt?nw=nwuserajhajh503\n",
    "\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/Leaky_T.svg)\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/Leaky_V.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ajhaj\\git\\link_dl\\_04_homeworks_solution\\homework_2\\wandb\\run-20241018_024733-ufj393tk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/ufj393tk' target=\"_blank\">2024-10-18_02-47-33</a></strong> to <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/ufj393tk' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/ufj393tk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x000001DB714F8E50>\n",
      "{'epochs': 2000, 'batch_size': 512, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20]}\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5668, Validation loss 0.5775\n",
      "Epoch 200, Training loss 0.5525, Validation loss 0.6186\n",
      "Epoch 300, Training loss 0.5248, Validation loss 0.5759\n",
      "Epoch 400, Training loss 0.5058, Validation loss 0.5006\n",
      "Epoch 500, Training loss 0.4826, Validation loss 0.4879\n",
      "Epoch 600, Training loss 0.4659, Validation loss 0.5259\n",
      "Epoch 700, Training loss 0.4404, Validation loss 0.4956\n",
      "Epoch 800, Training loss 0.4320, Validation loss 0.5646\n",
      "Epoch 900, Training loss 0.4256, Validation loss 0.4869\n",
      "Epoch 1000, Training loss 0.4396, Validation loss 0.4716\n",
      "Epoch 1100, Training loss 0.4278, Validation loss 0.5464\n",
      "Epoch 1200, Training loss 0.4061, Validation loss 0.4723\n",
      "Epoch 1300, Training loss 0.4011, Validation loss 0.4616\n",
      "Epoch 1400, Training loss 0.3855, Validation loss 0.4764\n",
      "Epoch 1500, Training loss 0.3840, Validation loss 0.5716\n",
      "Epoch 1600, Training loss 0.3863, Validation loss 0.5703\n",
      "Epoch 1700, Training loss 0.3694, Validation loss 0.5042\n",
      "Epoch 1800, Training loss 0.3920, Validation loss 0.4656\n",
      "Epoch 1900, Training loss 0.3638, Validation loss 0.4812\n",
      "Epoch 2000, Training loss 0.3502, Validation loss 0.5254\n",
      "submission_test.csv 파일이 생성되었습니다!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>Training loss</td><td>███▇▇▇▇▇▆▇▅▄▄▅▄▄▃▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁</td></tr><tr><td>Validation loss</td><td>▅▅▄▅▅▅▅▄▅▄▃▅▅▂█▃▄▁▂▂▁▁▁▁▄▂▄▂▁█▆▁▂▂▃▁▃▃▇▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>2000</td></tr><tr><td>Training loss</td><td>0.35018</td></tr><tr><td>Validation loss</td><td>0.52537</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-10-18_02-47-33</strong> at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/ufj393tk' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/ufj393tk</a><br/> View project at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241018_024733-ufj393tk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PReLU로 변경, 그외 전부 동일\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            #wandb.config.n_hidden_unit_list[0] 에서 설정된 첫 번째 히든레이어 노드 수\n",
    "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "            nn.PReLU(num_parameters=1, init=0.25),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.PReLU(num_parameters=1, init=0.25),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter Notebook 환경을 확인하여 argparse를 우회.\n",
    "    if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "        # 기본값을 설정\n",
    "        class Args:\n",
    "            wandb = True\n",
    "            batch_size = 512\n",
    "            epochs = 2000 # Early stopping을 위해 epochs를 2000으로 설정\n",
    "\n",
    "        args = Args() # args 추가\n",
    "        main(args) # 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PReLU 활성화 함수\n",
    "---\n",
    "https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/3mhrerpw?nw=nwuserajhajh503\n",
    "\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/PRelu_T.svg)\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/PRelu_V.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[요구 사항3]\n",
    "---\n",
    "테스트 및 submission.csv 생성\n",
    "\n",
    "오버피팅으로 인해 Activation Function 차이를 보기 힘들었음.\n",
    "\n",
    "따라서 제일 가성비 좋은 기본 Relu를 사용해서 모델을 구성하고, 수업시간에 배운 Early Stopping을 사용해\n",
    "\n",
    "Validation이 지속해서 증가하면 훈련을 멈추게 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ajhaj\\git\\link_dl\\_04_homeworks_solution\\homework_2\\wandb\\run-20241018_024917-7cfdilmc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/7cfdilmc' target=\"_blank\">2024-10-18_02-49-17</a></strong> to <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/7cfdilmc' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/7cfdilmc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x000001DB71542DD0>\n",
      "{'epochs': 2000, 'batch_size': 512, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20]}\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5717, Validation loss 0.5569\n",
      "Epoch 200, Training loss 0.5581, Validation loss 0.5758\n",
      "Epoch 300, Training loss 0.5438, Validation loss 0.5753\n",
      "Epoch 400, Training loss 0.5261, Validation loss 0.6289\n",
      "Epoch 500, Training loss 0.4998, Validation loss 0.5295\n",
      "Epoch 600, Training loss 0.4732, Validation loss 0.4898\n",
      "Epoch 700, Training loss 0.4526, Validation loss 0.5931\n",
      "Epoch 800, Training loss 0.4337, Validation loss 0.4789\n",
      "Epoch 900, Training loss 0.4142, Validation loss 0.5368\n",
      "Epoch 1000, Training loss 0.4186, Validation loss 0.5575\n",
      "Early stopping at epoch 1070. Best validation loss: 0.4487\n",
      "submission_test.csv 파일이 생성되었습니다!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▂▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>Training loss</td><td>████▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▃▄▃▃▃▃▂▃▂▂▃▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation loss</td><td>▆▇▆▇▆▇▆▅▄▅▆█▅▄▅▄▅▅▄▃▃▇▂▃▃▂▂▂▃▂▅▄▃▃▁▁▅▃▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1070</td></tr><tr><td>Training loss</td><td>0.41197</td></tr><tr><td>Validation loss</td><td>0.57084</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-10-18_02-49-17</strong> at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/7cfdilmc' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/7cfdilmc</a><br/> View project at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241018_024917-7cfdilmc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader, args):\n",
    "    n_epochs = wandb.config.epochs\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    best_validation_loss = float('inf')\n",
    "    patience_counter = 0  # Early stopping을 위한 patience 카운터\n",
    "    next_print_epoch = 100 # 100번마다 출력\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()  # 학습 모드 전환\n",
    "        loss_train = 0.0\n",
    "        num_trains = 0\n",
    "        for train_batch in train_data_loader:\n",
    "            input, target = train_batch['input'], train_batch['target']\n",
    "            output_train = model(input)\n",
    "            loss = loss_fn(output_train, target)\n",
    "            loss_train += loss.item()\n",
    "            num_trains += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % args.validation_intervals == 0:  # 10번마다 검증 실행\n",
    "            model.eval()  # 평가 모드 전환\n",
    "            loss_validation = 0.0\n",
    "            num_validations = 0\n",
    "            with torch.no_grad():\n",
    "                for validation_batch in validation_data_loader:\n",
    "                    input, target = validation_batch['input'], validation_batch['target']\n",
    "                    output_validation = model(input)\n",
    "                    loss = loss_fn(output_validation, target)\n",
    "                    loss_validation += loss.item()\n",
    "                    num_validations += 1\n",
    "\n",
    "            avg_validation_loss = loss_validation / num_validations\n",
    "            wandb.log({\n",
    "                \"Epoch\": epoch,\n",
    "                \"Training loss\": loss_train / num_trains,\n",
    "                \"Validation loss\": avg_validation_loss\n",
    "            })\n",
    "\n",
    "            # Early stopping 조건 확인\n",
    "            if avg_validation_loss + 0.00001< best_validation_loss:\n",
    "                best_validation_loss = avg_validation_loss\n",
    "                patience_counter = 0  # 성능이 개선되면 patience 초기화\n",
    "            else:\n",
    "                patience_counter += 1  # 개선되지 않으면 카운터 증가\n",
    "\n",
    "            if patience_counter >= args.early_stop_patience:  # patience 초과 시 학습 종료\n",
    "                print(f\"Early stopping at epoch {epoch}. Best validation loss: {best_validation_loss:.4f}\")\n",
    "                break\n",
    "            if epoch >= next_print_epoch:\n",
    "                print(\n",
    "                    f\"Epoch {epoch}, \"\n",
    "                    f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "                    f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "                )\n",
    "                next_print_epoch += 100\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            #wandb.config.n_hidden_unit_list[0] 에서 설정된 첫 번째 히든레이어 노드 수\n",
    "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def main(args):\n",
    "    #현재 시간 기록\n",
    "    current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    #모델에 설정할 값들을 담은 딕셔너리\n",
    "    #에포크, 배치사이즈, 러닝 레이트, 히든 유닛 개수 등 포함되어 있음\n",
    "    config = {\n",
    "        'epochs': args.epochs,\n",
    "        'batch_size': args.batch_size,\n",
    "        'learning_rate': 1e-3,\n",
    "        'n_hidden_unit_list': [20, 20],\n",
    "    }\n",
    "\n",
    "    #wandb 모델의 초기값 생성\n",
    "    wandb.init(\n",
    "        mode=\"online\" if args.wandb else \"disabled\",\n",
    "        project=\"my_model_training\",\n",
    "        notes=\"Titanic Dataset experiment\",\n",
    "        tags=[\"my_model\", \"titanic\"],\n",
    "        name=current_time_str,\n",
    "        config=config\n",
    "    )\n",
    "    print(args)\n",
    "    print(wandb.config)\n",
    "\n",
    "    #모델과 옵티마이저 생성\n",
    "    model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "    print(\"#\" * 50, 1)\n",
    "\n",
    "    #모델 train 시작.\n",
    "    training_loop(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        train_data_loader=train_data_loader,\n",
    "        validation_data_loader=validation_data_loader,\n",
    "        args=args # args 추가\n",
    "    )\n",
    "    #train 끝\n",
    "    #test 실행\n",
    "    test_and_create_submission(model, test_data_loader)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "        # 기본값을 설정\n",
    "        class Args:\n",
    "            wandb = True\n",
    "            batch_size = 512\n",
    "            epochs = 2000 # Early stopping을 위해 epochs를 2000으로 설정\n",
    "            validation_intervals = 10\n",
    "            early_stop_patience = 20\n",
    "\n",
    "        args = Args() # args 추가\n",
    "        main(args) # 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early-Stop\n",
    "---\n",
    "https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/dybp8t2f?nw=nwuserajhajh503\n",
    "\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/Early_T.svg)\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/Early_V.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[요구 사항4]\n",
    "---\n",
    "submission.csv 제출 및 등수확인\n",
    "\n",
    "오버피팅을 줄이기 위해 다양한 정규화 추가\n",
    "변경된 사항으로는 히든레이어 추가, 옵티마이저 변경, 배치 정규화, 드롭 아웃, 하이퍼파라미터 조정 등 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ajhaj\\git\\link_dl\\_04_homeworks_solution\\homework_2\\wandb\\run-20241018_025005-bg6gou1o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/bg6gou1o' target=\"_blank\">2024-10-18_02-50-05</a></strong> to <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/bg6gou1o' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/bg6gou1o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x000001DB6E8D6920>\n",
      "{'epochs': 1500, 'batch_size': 512, 'learning_rate': 0.0005, 'n_hidden_unit_list': [64, 32, 16]}\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.4345, Validation loss 0.5794\n",
      "Epoch 200, Training loss 0.3957, Validation loss 0.4565\n",
      "Epoch 300, Training loss 0.3987, Validation loss 0.4923\n",
      "Epoch 400, Training loss 0.3957, Validation loss 0.4495\n",
      "Epoch 500, Training loss 0.3897, Validation loss 0.4936\n",
      "Epoch 600, Training loss 0.3942, Validation loss 0.4515\n",
      "Epoch 700, Training loss 0.3785, Validation loss 0.4574\n",
      "Epoch 800, Training loss 0.3671, Validation loss 0.5478\n",
      "Early stopping at epoch 900. Best validation loss: 0.4495\n",
      "submission_test.csv 파일이 생성되었습니다!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>Training loss</td><td>█▅▅▄▄▄▃▂▃▃▂▃▃▃▃▂▃▃▂▂▃▂▂▂▂▂▂▂▁▂▁▃▂▁▃▂▁▁▂▁</td></tr><tr><td>Validation loss</td><td>█▆▂▃▄▂▁▃▄▁▁▁▃▁▂▁█▇▁▁▅▃▃▅▁▁▁▃▁▂▁▂▅▃▂▄▂▅▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>900</td></tr><tr><td>Training loss</td><td>0.3679</td></tr><tr><td>Validation loss</td><td>0.46997</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-10-18_02-50-05</strong> at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/bg6gou1o' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training/runs/bg6gou1o</a><br/> View project at: <a href='https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ajhajh503-korea-university-of-technology-and-education/my_model_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241018_025005-bg6gou1o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),  # n_input을 실제 입력 크기로 수정\n",
    "            nn.BatchNorm1d(wandb.config.n_hidden_unit_list[0]), # batch_normalziation 추가\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.BatchNorm1d(wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            #히든 레이어 추가\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[1], wandb.config.n_hidden_unit_list[2]),\n",
    "            nn.BatchNorm1d(wandb.config.n_hidden_unit_list[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[2], n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def get_model_and_optimizer():\n",
    "    n_input = 11\n",
    "    n_output = 2\n",
    "    model = MyModel(n_input=n_input, n_output=n_output)\n",
    "\n",
    "    #SGD에서 ADAM으로 변경\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "    return model, optimizer\n",
    "\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader, args):\n",
    "    n_epochs = wandb.config.epochs\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    best_validation_loss = float('inf')\n",
    "    patience_counter = 0  # Early stopping을 위한 patience 카운터\n",
    "    next_print_epoch = 100\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()  # 학습 모드 전환\n",
    "        loss_train = 0.0\n",
    "        num_trains = 0\n",
    "        for train_batch in train_data_loader:\n",
    "            input, target = train_batch['input'], train_batch['target']\n",
    "            output_train = model(input)\n",
    "            loss = loss_fn(output_train, target)\n",
    "            loss_train += loss.item()\n",
    "            num_trains += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % args.validation_intervals == 0:  # 10번마다 검증 실행\n",
    "            model.eval()  # 평가 모드 전환\n",
    "            loss_validation = 0.0\n",
    "            num_validations = 0\n",
    "            with torch.no_grad():\n",
    "                for validation_batch in validation_data_loader:\n",
    "                    input, target = validation_batch['input'], validation_batch['target']\n",
    "                    output_validation = model(input)\n",
    "                    loss = loss_fn(output_validation, target)\n",
    "                    loss_validation += loss.item()\n",
    "                    num_validations += 1\n",
    "\n",
    "            avg_validation_loss = loss_validation / num_validations\n",
    "            wandb.log({\n",
    "                \"Epoch\": epoch,\n",
    "                \"Training loss\": loss_train / num_trains,\n",
    "                \"Validation loss\": avg_validation_loss\n",
    "            })\n",
    "\n",
    "            # Early stopping 조건 확인\n",
    "            if avg_validation_loss + 0.00001< best_validation_loss:\n",
    "                best_validation_loss = avg_validation_loss\n",
    "                patience_counter = 0  # 성능이 개선되면 patience 초기화\n",
    "            else:\n",
    "                patience_counter += 1  # 개선되지 않으면 카운터 증가\n",
    "\n",
    "            if patience_counter >= args.early_stop_patience:  # patience 초과 시 학습 종료\n",
    "                print(f\"Early stopping at epoch {epoch}. Best validation loss: {best_validation_loss:.4f}\")\n",
    "                break\n",
    "            if epoch >= next_print_epoch:\n",
    "                print(\n",
    "                    f\"Epoch {epoch}, \"\n",
    "                    f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "                    f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "                )\n",
    "                next_print_epoch += 100\n",
    "\n",
    "def test_and_create_submission(model, test_data_loader):\n",
    "    model.eval()  # 모델을 평가 모드로 전환\n",
    "    all_predictions = []\n",
    "    passenger_ids = list(range(892, 892 + len(test_data_loader.dataset)))  # Titanic 테스트 데이터의 승객 ID는 892부터 시작\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_batch in test_data_loader:\n",
    "            input = test_batch['input']  # TitanicTestDataset을 사용하여 'input' 데이터를 가져옴\n",
    "            output = model(input)\n",
    "            predictions = torch.argmax(output, dim=1).cpu().numpy()  # 가장 높은 확률의 클래스를 예측\n",
    "            all_predictions.extend(predictions)\n",
    "\n",
    "    # submission.csv 생성\n",
    "    submission_df = pd.DataFrame({\n",
    "        'PassengerId': passenger_ids,\n",
    "        'Survived': all_predictions\n",
    "    })\n",
    "    submission_df.to_csv('submission_test.csv', index=False)\n",
    "    print(\"submission_test.csv 파일이 생성되었습니다!\")\n",
    "\n",
    "def main(args):\n",
    "    #현재 시간 기록\n",
    "    current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    #모델에 설정할 값들을 담은 딕셔너리\n",
    "    #에포크, 배치사이즈, 러닝 레이트, 히든 유닛 개수 등 포함되어 있음\n",
    "    config = {\n",
    "        'epochs': args.epochs,\n",
    "        'batch_size': args.batch_size,\n",
    "        'learning_rate': 5e-4,\n",
    "        'n_hidden_unit_list': [64, 32, 16],\n",
    "    }\n",
    "\n",
    "    #wandb 모델의 초기값 생성\n",
    "    wandb.init(\n",
    "        mode=\"online\" if args.wandb else \"disabled\",\n",
    "        project=\"my_model_training\",\n",
    "        notes=\"Titanic Dataset experiment\",\n",
    "        tags=[\"my_model\", \"titanic\"],\n",
    "        name=current_time_str,\n",
    "        config=config\n",
    "    )\n",
    "    print(args)\n",
    "    print(wandb.config)\n",
    "\n",
    "    #모델과 옵티마이저 생성\n",
    "    model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "    print(\"#\" * 50, 1)\n",
    "\n",
    "    #모델 train 시작.\n",
    "    training_loop(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        train_data_loader=train_data_loader,\n",
    "        validation_data_loader=validation_data_loader,\n",
    "        args=args # args 추가\n",
    "    )\n",
    "    #train 끝\n",
    "    #test 실행\n",
    "    test_and_create_submission(model, test_data_loader)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "        class Args:\n",
    "            wandb = True\n",
    "            batch_size = 512\n",
    "            epochs = 1500 # Early stopping을 위해 epochs를 1000으로 설정\n",
    "            validation_intervals = 10\n",
    "            early_stop_patience = 50\n",
    "\n",
    "        args = Args() # args 추가\n",
    "        main(args) # 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission\n",
    "---\n",
    "\n",
    "![Relu Activation Function](https://raw.githubusercontent.com/ajh1004ajh00/link_dl/main/_04_homeworks_solution/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[숙제 후기]\n",
    "---\n",
    "titanic dataset을 이용해 모델을 직접 설계해보는 실습을 해 보았습니다.\n",
    "\n",
    "제일 기억에 남는것은 Loss는 감소하는 반면 validation Loss는 개선되지 않는 오버피팅 현상을 겪었습니다.\n",
    "\n",
    "이를 해결하기 위해 Batch Normalization, Dropout, 하이퍼파라미터 조정 등 다양하게 해 보았지만 성능차이가 크게 나지 않았습니다.\n",
    "\n",
    "처음보단 오버피팅을 완화하긴 했지만 그 차이가 크지 않아 아쉬웠습니다.\n",
    "\n",
    "이번 과제를 통해 딥러닝 모델의 학습 과정에서 발생할 수 있는 문제들을 이해하고,\n",
    "이를 해결하기 위한 다양한 기법들을 실제로 적용해 볼 수 있었습니다.\n",
    "또한, 하이퍼파라미터 튜닝이 진짜 어렵다는 것을 알게된 시간이였습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "link_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
